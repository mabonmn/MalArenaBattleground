#!/usr/bin/env python3
"""
Malware Detection API for Competition
Uses trained LightGBM model with EMBER feature extraction

Competition Requirements:
- Listen on port 8080
- Accept POST / with Content-Type: application/octet-stream
- Return {"result": 0} for benign, {"result": 1} for malicious
- FPR < 1%, FNR < 10%
- Response time < 5 seconds for files up to 2 MiB
- Memory limit: 1.5GB, 1 CPU
"""

import os
import json
import numpy as np
import lightgbm as lgb
from pathlib import Path
from flask import Flask, request, jsonify
import logging
import time

# Import EMBER feature extraction
try:
    import ember
    EMBER_AVAILABLE = True
except ImportError:
    EMBER_AVAILABLE = False
    logging.error("EMBER library not available - feature extraction will fail")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MalwareDetector:
    """
    Malware detection API using trained LightGBM model with EMBER features
    """
    
    def __init__(self, model_path: str, threshold: float = 0.5):
        """
        Initialize the detector with a trained model
        
        Args:
            model_path: Path to the saved LightGBM model
            threshold: Classification threshold (default: 0.5)
        """
        self.model_path = Path(model_path)
        self.threshold = threshold
        self.model = None
        self.feature_extractor = None
        self.load_model()
        self.init_feature_extractor()
    
    def load_model(self):
        """Load the trained LightGBM model"""
        try:
            if not self.model_path.exists():
                raise FileNotFoundError(f"Model file not found: {self.model_path}")
            
            self.model = lgb.Booster(model_file=str(self.model_path))
            logger.info(f"Model loaded successfully from {self.model_path}")
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            raise e
    
    def init_feature_extractor(self):
        """Initialize EMBER feature extractor"""
        try:
            if EMBER_AVAILABLE:
                self.feature_extractor = ember.PEFeatureExtractor()
                logger.info("EMBER feature extractor initialized")
            else:
                logger.error("EMBER not available - cannot initialize feature extractor")
                raise ImportError("EMBER library is required")
        except Exception as e:
            logger.error(f"Failed to initialize feature extractor: {e}")
            raise e
    
    def extract_features(self, pe_bytes: bytes) -> np.ndarray:
        """
        Extract EMBER features from PE file bytes
        
        Args:
            pe_bytes: Raw bytes of PE file
            
        Returns:
            Feature vector as numpy array
        """
        try:
            # Extract features using EMBER
            features = self.feature_extractor.feature_vector(pe_bytes)
            
            if features is None:
                logger.warning("Feature extraction returned None, using zero vector")
                return np.zeros(2381, dtype=np.float32)  # EMBER has 2381 features
            
            # Convert to numpy array and handle any missing values
            features = np.array(features, dtype=np.float32)
            
            # Handle NaN values (replace with 0)
            features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)
            
            return features
            
        except Exception as e:
            logger.error(f"Feature extraction failed: {e}")
            # Return zero vector as fallback (will likely classify as benign)
            return np.zeros(2381, dtype=np.float32)
    
    def predict(self, pe_bytes: bytes) -> int:
        """
        Predict if PE file is malware (1) or benign (0)
        
        Args:
            pe_bytes: Raw bytes of PE file
            
        Returns:
            0 for benign, 1 for malicious
        """
        try:
            start_time = time.time()
            
            # Extract features
            features = self.extract_features(pe_bytes)
            
            # Reshape for prediction
            features = features.reshape(1, -1)
            
            # Make prediction
            prediction = self.model.predict(features)[0]
            
            # Convert to binary classification
            result = 1 if prediction > self.threshold else 0
            
            prediction_time = time.time() - start_time
            logger.info(f"Prediction: {prediction:.4f}, Result: {result}, Time: {prediction_time:.3f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            # Default to benign on error (safer for false positive rate)
            return 0

def create_app(detector: MalwareDetector) -> Flask:
    """Create Flask app with malware detection endpoint"""
    app = Flask(__name__)
    
    @app.route('/', methods=['POST'])
    def detect_malware():
        """API endpoint for malware detection - competition format"""
        try:
            start_time = time.time()
            
            # Check content type
            if request.content_type != 'application/octet-stream':
                logger.warning(f"Invalid content type: {request.content_type}")
                return jsonify({"result": 0})  # Default to benign for invalid requests
            
            # Get PE file bytes
            pe_bytes = request.get_data()
            
            if not pe_bytes:
                logger.warning("No file data received")
                return jsonify({"result": 0})
            
            # Check file size limit (2 MiB = 2^21 bytes)
            if len(pe_bytes) > 2**21:
                logger.warning(f"File too large: {len(pe_bytes)} bytes")
                return jsonify({"result": 0})  # Default to benign for oversized files
            
            # Make prediction
            result = detector.predict(pe_bytes)
            
            total_time = time.time() - start_time
            logger.info(f"Total request time: {total_time:.3f}s")
            
            # Competition requires specific JSON format
            return jsonify({"result": result})
            
        except Exception as e:
            logger.error(f"API error: {e}")
            # Default to benign on error (safer for competition)
            return jsonify({"result": 0})
    
    @app.route('/health', methods=['GET'])
    def health_check():
        """Health check endpoint"""
        return jsonify({"status": "healthy", "model_loaded": detector.model is not None})
    
    return app

def main():
    """Main function to run the API"""
    # Get configuration from environment variables
    model_path = os.getenv('MODEL_PATH', '../models/malware_lightgbm_200sample_model.txt')
    threshold = float(os.getenv('THRESHOLD', '0.5'))
    port = int(os.getenv('PORT', '8080'))
    host = os.getenv('HOST', '0.0.0.0')
    
    logger.info(f"Starting malware detection API...")
    logger.info(f"Model path: {model_path}")
    logger.info(f"Threshold: {threshold}")
    logger.info(f"Host: {host}, Port: {port}")
    
    # Check if model exists
    if not os.path.exists(model_path):
        logger.error(f"Model file not found: {model_path}")
        logger.error("Please ensure the trained model is available")
        exit(1)
    
    try:
        # Initialize detector
        detector = MalwareDetector(model_path, threshold)
        
        # Create Flask app
        app = create_app(detector)
        
        # Run the app
        logger.info("API server starting...")
        app.run(host=host, port=port, debug=False, threaded=True)
        
    except Exception as e:
        logger.error(f"Failed to start API: {e}")
        exit(1)

if __name__ == "__main__":
    main()