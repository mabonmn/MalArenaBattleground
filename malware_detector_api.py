#!/usr/bin/env python3
"""
Flask API for Malware Detection Service
MLSEC Competition Docker Implementation

This API serves the trained LightGBM model via HTTP requests
with competition constraints compliance.

Requirements:
- FPR ≤ 1%
- TPR ≥ 95%
- Memory ≤ 1GB RAM
- Response time ≤ 5 seconds per sample
"""

import os
import sys
import json
import time
import pickle
import logging
from pathlib import Path
from typing import Dict, Any, Optional

import numpy as np
import lightgbm as lgb
from flask import Flask, request, jsonify
import psutil

# Import EMBER feature extraction
try:
    import ember
    EMBER_AVAILABLE = True
except ImportError:
    EMBER_AVAILABLE = False

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)

class MalwareDetectorAPI:
    """
    Malware detection API service
    """
    
    def __init__(self, model_path: str = "malware_detector_sample.pkl"):
        """
        Initialize the API with trained model
        
        Args:
            model_path: Path to the trained model file
        """
        self.model_path = model_path
        self.model = None
        self.feature_extractor = None
        self.optimal_threshold = 0.5  # Will be loaded from model metadata
        
        # Performance tracking
        self.request_count = 0
        self.total_response_time = 0
        
        # Load model
        self.load_model()
        
        logger.info("Malware Detector API initialized successfully")
    
    def load_model(self) -> None:
        """Load the trained model using EMBER's format"""
        try:
            # Try to load EMBER's native model format first
            ember_model_path = "ember2018/ember_model_2018.txt"
            if os.path.exists(ember_model_path):
                self.model = lgb.Booster(model_file=ember_model_path)
                logger.info(f"Loaded EMBER model from {ember_model_path}")
            else:
                # Fallback to pickle format
                if not os.path.exists(self.model_path):
                    raise FileNotFoundError(f"Model file not found: {self.model_path}")
                
                with open(self.model_path, 'rb') as f:
                    model_data = pickle.load(f)
                
                self.model = model_data['model']
                logger.info(f"Loaded pickled model from {self.model_path}")
            
            self.feature_dim = 2381  # EMBER standard feature dimension
            
            # Try to load optimal threshold from training results
            results_path = self.model_path.replace('.pkl', '_results.json')
            if os.path.exists(results_path):
                with open(results_path, 'r') as f:
                    results = json.load(f)
                    self.optimal_threshold = results.get('optimal_threshold', 0.5)
            
            logger.info(f"Feature dimension: {self.feature_dim}")
            logger.info(f"Optimal threshold: {self.optimal_threshold}")
            
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            raise e
    
    def extract_features(self, file_data: bytes) -> Optional[np.ndarray]:
        """
        Extract EMBER features from PE file data
        
        Args:
            file_data: Raw PE file bytes
        
        Returns:
            Feature vector or None if extraction fails
        """
        try:
            if not EMBER_AVAILABLE:
                logger.error("EMBER library not available for feature extraction")
                return None
            
            # Use EMBER library for feature extraction
            features = ember.features.PEFeatureExtractor().feature_vector(file_data)
            
            if features is None or len(features) != self.feature_dim:
                logger.warning(f"Invalid feature vector length: {len(features) if features else 'None'}")
                return None
            
            # Handle NaN and infinite values
            features = np.array(features, dtype=np.float32)
            
            # Replace NaN with 0
            nan_mask = np.isnan(features)
            if np.any(nan_mask):
                features[nan_mask] = 0
            
            # Replace infinite values with large finite values
            features = np.clip(features, -1e6, 1e6)
            
            return features.reshape(1, -1)  # Reshape for single prediction
            
        except Exception as e:
            logger.error(f"Feature extraction failed: {e}")
            return None
    
    def predict_sample(self, file_data: bytes) -> Dict[str, Any]:
        """
        Predict malware probability using EMBER's prediction function
        
        Args:
            file_data: Raw PE file bytes
        
        Returns:
            Dictionary containing prediction results
        """
        start_time = time.time()
        
        try:
            if EMBER_AVAILABLE:
                # Use EMBER's built-in prediction function
                probability = ember.predict_sample(self.model, file_data)
            else:
                # Fallback to manual feature extraction
                features = self.extract_features(file_data)
                if features is None:
                    return {
                        'error': 'Feature extraction failed',
                        'prediction': 'unknown',
                        'probability': 0.5,
                        'response_time': time.time() - start_time
                    }
                
                # Make prediction
                probability = self.model.predict(features, num_iteration=self.model.best_iteration)[0]
            
            # Apply optimal threshold
            is_malware = probability >= self.optimal_threshold
            prediction = 'malware' if is_malware else 'benign'
            
            response_time = time.time() - start_time
            
            # Update performance tracking
            self.request_count += 1
            self.total_response_time += response_time
            
            result = {
                'prediction': prediction,
                'probability': float(probability),
                'threshold': self.optimal_threshold,
                'response_time': response_time,
                'features_extracted': True
            }
            
            # Log prediction for monitoring
            if self.request_count % 100 == 0 or response_time > 4.0:
                logger.info(f"Prediction: {prediction} (prob: {probability:.4f}, time: {response_time:.3f}s)")
            
            return result
            
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            return {
                'error': str(e),
                'prediction': 'unknown',
                'probability': 0.5,
                'response_time': time.time() - start_time
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get API performance statistics"""
        avg_response_time = (
            self.total_response_time / self.request_count 
            if self.request_count > 0 else 0
        )
        
        memory = psutil.virtual_memory()
        
        return {
            'requests_processed': self.request_count,
            'average_response_time': avg_response_time,
            'memory_usage_gb': (memory.total - memory.available) / (1024**3),
            'memory_usage_percent': memory.percent,
            'model_loaded': self.model is not None
        }


# Initialize global detector
detector = None

@app.before_first_request
def initialize_detector():
    """Initialize the detector before first request"""
    global detector
    detector = MalwareDetectorAPI()

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        if detector is None:
            return jsonify({'status': 'error', 'message': 'Detector not initialized'}), 500
        
        stats = detector.get_stats()
        
        return jsonify({
            'status': 'healthy',
            'memory_usage_gb': stats['memory_usage_gb'],
            'requests_processed': stats['requests_processed'],
            'average_response_time': stats['average_response_time']
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/predict', methods=['POST'])
def predict_malware():
    """Main prediction endpoint"""
    try:
        if detector is None:
            return jsonify({'error': 'Detector not initialized'}), 500
        
        # Check if file is provided
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # Read file data
        file_data = file.read()
        
        # Check file size (max 5MB as per competition rules)
        if len(file_data) > 5 * 1024 * 1024:
            return jsonify({'error': 'File too large (max 5MB)'}), 400
        
        # Make prediction
        result = detector.predict_sample(file_data)
        
        # Check response time constraint
        if result.get('response_time', 0) > 5.0:
            logger.warning(f"Response time exceeded: {result['response_time']:.3f}s")
            return jsonify({'error': 'Request timeout (>5s)', 'result': result}), 408
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Prediction endpoint error: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/stats', methods=['GET'])
def get_stats():
    """Get API statistics"""
    try:
        if detector is None:
            return jsonify({'error': 'Detector not initialized'}), 500
        
        stats = detector.get_stats()
        return jsonify(stats)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/', methods=['GET'])
def index():
    """API information endpoint"""
    return jsonify({
        'service': 'Malware Detection API',
        'version': '1.0',
        'endpoints': {
            'POST /predict': 'Upload PE file for malware detection',
            'GET /health': 'Health check',
            'GET /stats': 'API performance statistics',
            'GET /': 'This information'
        },
        'constraints': {
            'max_file_size': '5MB',
            'max_response_time': '5 seconds',
            'memory_limit': '1GB'
        }
    })

@app.errorhandler(413)
def handle_file_too_large(error):
    """Handle file too large errors"""
    return jsonify({'error': 'File too large'}), 413

@app.errorhandler(500)
def handle_internal_error(error):
    """Handle internal server errors"""
    logger.error(f"Internal server error: {error}")
    return jsonify({'error': 'Internal server error'}), 500


def main():
    """Main function to run the API server"""
    # Check available memory
    memory = psutil.virtual_memory()
    available_gb = memory.available / (1024**3)
    
    if available_gb < 1.5:  # Need some headroom
        logger.warning(f"Low available memory: {available_gb:.2f}GB")
        logger.warning("This may affect performance")
    
    # Log system info
    logger.info(f"Available memory: {available_gb:.2f}GB")
    logger.info(f"CPU cores: {psutil.cpu_count()}")
    
    # Run Flask app
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False,  # Disable debug mode for production
        threaded=True,  # Enable threading for concurrent requests
        use_reloader=False  # Disable reloader to prevent double initialization
    )


if __name__ == "__main__":
    main()